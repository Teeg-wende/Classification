[["index.html", "Projet Apprentissage non supervisé Chapter 1 Prétraitement des Données 1.1 Description des variables 1.2 Les lignes incomplètes 1.3 Imputation knn 1.4 Normalisation de la base", " Projet Apprentissage non supervisé 22410464 OUEDRAOGO Teeg-wendé Inoussa 22407680 HASHAZINKA Orlana 22402636 MITOSSEDE Séphora Date de rendu du projet : 2025-05-02 23:09:55 Chapter 1 Prétraitement des Données 1.1 Description des variables     Le tableau 1 présente le résumé des variables de 420 individus, l’analyse des données montre que plusieurs variables présentent des valeurs manquantes (colonne p_na), avec un pourcentage maximal de 0,71 pour la variable ulnal. Toutefois, pour la majorité des variables, le taux de valeurs manquantes est inférieur à 10 %. Selon Schafer (1997), lorsque le taux de valeurs manquantes est modéré (inférieur à 10 %), il est acceptable de les imputer à l’aide de méthodes statistiques simples. Par conséquent, une stratégie d’imputation peut être mise en place sans risque majeur de biais. Table 1.1: Description des variables de la base bird variable q_zeros p_zeros q_na p_na q_inf p_inf type unique id 1 0.24 0 0.00 0 0 numeric 420 huml 0 0.00 1 0.24 0 0 numeric 407 humw 0 0.00 1 0.24 0 0 numeric 321 ulnal 0 0.00 3 0.71 0 0 numeric 398 ulnaw 0 0.00 2 0.48 0 0 numeric 308 feml 0 0.00 2 0.48 0 0 numeric 402 femw 0 0.00 1 0.24 0 0 numeric 290 tibl 0 0.00 2 0.48 0 0 numeric 405 tibw 0 0.00 1 0.24 0 0 numeric 288 tarl 0 0.00 1 0.24 0 0 numeric 409 tarw 0 0.00 1 0.24 0 0 numeric 279 type 0 0.00 0 0.00 0 0 character 6 Méthode d’imputation choisie : k-nearest neighbors ou knn Les variables comme huml, humw, ulnal, ulnaw, sont morphologiques et souvent liées entre elles (par exemple, des longueurs et des largeurs d’os), ce qui permet au KNN de trouver des voisins similaires de façon pertinente. 1.2 Les lignes incomplètes ligne_na &lt;- df %&gt;% filter(rowSums(is.na(.))&gt;0) id &lt;- select(ligne_na, id) %&gt;% pull() # Les numeros de lignes id contenant NA na_positions &lt;- which(is.na(ligne_na), arr.ind = TRUE) # Les cellules contenant NA ligne_na FALSE # A tibble: 7 × 12 FALSE id huml humw ulnal ulnaw feml femw tibl tibw tarl tarw type FALSE &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; FALSE 1 160 76.4 4.11 86.8 3.84 NA NA 67.1 2.48 41.6 2.1 W FALSE 2 204 63.8 4.74 NA NA 57.3 4.88 75.7 4.33 60.2 3.82 R FALSE 3 207 98.1 7.77 113. 5.76 82.0 7.17 107. 6.65 NA NA R FALSE 4 342 NA NA NA NA 32.5 2.65 55.1 2.81 38.9 2.25 SO FALSE 5 378 20.1 1.86 NA 1.52 17.2 1.22 NA NA 18.5 0.91 SO FALSE 6 396 16.5 1.47 20.6 1.43 15.9 1.27 NA 1.19 17.6 1.02 SO FALSE 7 404 20.4 1.87 22.2 1.6 NA 1.77 37.5 1.64 25.5 1.34 SO 1.3 Imputation knn 1.3.1 Choix du meilleur k Pour choisir le meilleur k pour l’imputation par k plus proches voisins (kNN), on a masqué aléatoirement 10 % des valeurs non manquantes de chaque variable avec des NA. Ensuite, on a testé différentes valeurs de k (de 1 à 10) pour imputer ces valeurs manquantes, et on a calculé l’erreur (RMSE) entre les valeurs réelles et imputées. Le k qui donne la plus petite erreur moyenne est sélectionné comme meilleur k. Table 1.2: Meilleur k d’imputation pour chaque variable huml humw ulnal ulnaw feml femw tibl tibw tarl tarw k 9 6 7 8 6 10 6 1 2 7 Pour sélectionner un k unique à utiliser globalement, nous avons choisi le k le plus fréquent parmi les meilleurs k individuels. Cette méthode permet de retenir une valeur de k qui fonctionne bien pour la majorité des variables, tout en assurant une imputation cohérente et simple à appliquer à l’ensemble du jeu de données, donc k = 6. 1.3.2 Application du knn df_imputed &lt;- kNN(data = df, variable = names(resultats_k), k = global_k, imp_var = FALSE) Table 1.3: Cellules imputées colorées id huml humw ulnal ulnaw feml femw tibl tibw tarl tarw type 161 160 76.43 4.11 86.79 3.84 47.46 2.835 67.13 2.48 41.65 2.1 W 205 204 63.76 4.74 39.265 3.455 57.33 4.88 75.67 4.33 60.19 3.82 R 208 207 98.08 7.77 113.04 5.76 82.04 7.17 107.47 6.65 81.615 6.125 R 343 342 43.065 3.81 53.39 2.86 32.54 2.65 55.06 2.81 38.94 2.25 SO 379 378 20.1 1.86 41.675 1.52 17.21 1.22 26.355 1.3 18.46 0.91 SO 397 396 16.51 1.47 20.56 1.43 15.88 1.27 26.15 1.19 17.63 1.02 SO 405 404 20.36 1.87 22.19 1.6 22.29 1.77 37.47 1.64 25.54 1.34 SO 1.4 Normalisation de la base df_scale &lt;- scale(select(df_imputed, -c(id, type))) head(df_scale) FALSE huml humw ulnal ulnaw feml femw FALSE [1,] 0.30086867 0.8104128 0.052352166 0.58888431 0.2479651 0.2374941 FALSE [2,] 0.45203847 0.7928772 0.197714369 0.91429927 0.5101103 0.5343397 FALSE [3,] 0.28580748 0.7016920 0.005433615 0.77221668 0.3111205 0.3364427 FALSE [4,] 0.24266923 0.4667147 -0.054280905 0.53846791 0.1592467 0.1484405 FALSE [5,] -0.03345273 0.1651020 -0.287508758 0.06180374 -0.1460046 -0.2473537 FALSE [6,] -0.04981551 0.1440593 -0.315318663 -0.05736230 0.6344163 0.5887614 FALSE tibl tibw tarl tarw FALSE [1,] -1.5586472 0.4096109 -0.02713657 0.41230000 FALSE [2,] 0.4159592 0.6403390 0.09329973 0.48997442 FALSE [3,] 0.2872609 0.4144178 -0.04391163 0.18384580 FALSE [4,] 0.1239436 0.1067804 -0.15273443 0.21582939 FALSE [5,] -0.2169614 -0.1047203 -0.32048499 0.08789503 FALSE [6,] -0.1989912 -0.2152775 -0.44135142 -0.04917749 "],["classification-des-oiseaux.html", "Chapter 2 Classification des Oiseaux 2.1 Classification Ascendante Hiérarchique 2.2 K-means 2.3 Modèles de mélanges 2.4 Clustering spectral", " Chapter 2 Classification des Oiseaux 2.1 Classification Ascendante Hiérarchique Objectif : Créer des groupes homogènes, la méthode de Ward ou le lien complet est préférable. Neanmoins testons plusieurs critères de fusion et cherchons à retenir le meilleur. dist_matrix &lt;- dist(df_scale) methods &lt;- c(&quot;single&quot;, &quot;complete&quot;, &quot;average&quot;, &quot;ward.D2&quot;) # Méthodes de fusion hc_list &lt;- list() # Liste pour stocker les résultats # Application de la CAH avec chaque méthode for (m in methods) { hc &lt;- hclust(dist_matrix, method = m) hc_list[[m]] &lt;- hc } ward_clusters &lt;- cutree(hc_list[[&quot;ward.D2&quot;]], k = 4) df$ward_clusters &lt;- ward_clusters 2.2 K-means 2.2.1 Méthode du coude pour choisir k choix du k : 3 2.2.2 Clustering avec le k choisi kmean_clusters &lt;- kmeans(df_scale, centers = 3, nstart = 25) df$kmean_clusters &lt;- as.factor(kmean_clusters$cluster) 2.3 Modèles de mélanges gmm &lt;- Mclust(df_scale) # Application du modèle de mélange gaussien df$melange_clusters &lt;- gmm$classification 2.4 Clustering spectral 2.4.1 Choix du meilleur k (Méthode de silhouette) choix du k : 6 spectral_res &lt;- specc(df_scale, centers = 6) df$spectral_cluster &lt;- as.factor(spectral_res) "],["comparaison-des-résultats.html", "Chapter 3 Comparaison des Résultats 3.1 CAH 3.2 K-means 3.3 Méthode de mélanges 3.4 Clustering spectral 3.5 Conclusion", " Chapter 3 Comparaison des Résultats 3.1 CAH Les résultats obtenus avec la CAH varient selon la méthode de fusion utilisée. La méthode single produit des clusters peu pertinents en raison de l’effet de chaînage. En revanche, ward.D2 génère des clusters bien séparés et compacts, ce qui en fait la méthode hiérarchique la plus convaincante dans ce cas. 3.2 K-means K-means affiche également de bons résultats, avec trois groupes distincts visibles dans la projection PCA. Toutefois, il repose sur l’hypothèse de clusters sphériques et peut être sensible aux points initiaux. 3.3 Méthode de mélanges Le modèle de mélange gaussien permet de modéliser les données comme une combinaison de plusieurs lois normales. L’analyse du critère BIC montre que le modèle optimal comporte 3 composantes, ce qui est cohérent avec les autres méthodes (K-means, CAH). Le modèle VEV ou similaire offre la meilleure valeur de BIC. La matrice de dispersion indique une séparation claire entre les clusters, avec des formes elliptiques qui s’ajustent bien à la structure des données, ce qui constitue un avantage par rapport à K-means qui impose des clusters sphériques. Ce modèle est donc particulièrement adapté lorsque la forme et l’orientation des groupes varient. FALSE ---------------------------------------------------- FALSE Gaussian finite mixture model fitted by EM algorithm FALSE ---------------------------------------------------- FALSE FALSE Mclust VEE (ellipsoidal, equal shape and orientation) model with 9 components: FALSE FALSE log-likelihood n df BIC ICL FALSE 1293.25 420 161 1614.02 1547.736 FALSE FALSE Clustering table: FALSE 1 2 3 4 5 6 7 8 9 FALSE 64 57 12 43 41 55 65 14 69 3.4 Clustering spectral Le Clustering spectral présente six clusters, une séparation claire entre certains clusters, notamment le Cluster 1 (rouge) et le Cluster 3 (vert). Certains clusters se chevauchent, ce qui peut indiquer que certaines groupes de données sont moins distincts. 3.5 Conclusion Chaque méthode de clustering produit des résultats variés en termes de séparation et de distinctivité des clusters. Clustering spectral et K-means semblent offrir de bons résultats. Les méthodes de fusion montrent une hiérarchie différente qui peut également être pertinente. "],["clusters-vs-classes-réelles.html", "Chapter 4 Clusters vs Classes Réelles 4.1 CAH 4.2 K-means 4.3 Méthode de mélanges 4.4 Clustering spectral", " Chapter 4 Clusters vs Classes Réelles 4.1 CAH Le croisement entre les clusters morphologiques et les types écologiques met en évidence des tendances intéressantes. Le cluster 2, le plus important en effectif, regroupe majoritairement des percheurs et chanteurs (types P et SO), ce qui témoigne de morphologies légères et adaptées à la vie arboricole. Le cluster 1, quant à lui, combine nageurs, échassiers et rapaces, indiquant des oiseaux à morphologies plus robustes ou spécialisées (par exemple, pour la pêche ou la chasse). Le cluster 3 contient presque exclusivement des nageurs et rapaces, soulignant une autre forme d’adaptation morphologique. Enfin, le cluster 4, très restreint, semble rassembler des individus atypiques, peut-être isolés morphologiquement des grandes tendances. # Tableau croisé entre les clusters et les types table(df$ward_clusters, df$type) FALSE FALSE P R SO SW T W FALSE 1 4 19 0 39 1 29 FALSE 2 34 11 128 30 19 26 FALSE 3 0 20 0 42 1 8 FALSE 4 0 0 0 5 2 2 4.2 K-means Le cluster 3 regroupe majoritairement les oiseaux de type SO (125/235), indiquant une bonne cohérence morphologique pour cette classe. Le cluster 1 contient principalement des oiseaux SW (56) et W (32), montrant un regroupement partiel basé sur des morphologies aquatiques. En revanche, le cluster 3 est plus hétérogène, partagé entre R (19) et SW (33), ce qui révèle un chevauchement morphologique entre rapaces et nageurs. Globalement, les clusters reflètent certaines tendances écologiques, mais avec des recouvrements notables. table(df$kmean_clusters, df$type) FALSE FALSE P R SO SW T W FALSE 1 5 22 3 56 5 32 FALSE 2 0 19 0 33 3 7 FALSE 3 33 9 125 27 15 26 4.3 Méthode de mélanges Le croisement entre les clusters issus du modèle de mélange gaussien et les classes écologiques connues confirme la capacité du GMM à capturer des tendances morphologiques cohérentes. Certains clusters, comme le cluster 9 (66 songbirds) ou le cluster 3 (12 nageurs), correspondent presque parfaitement à un type écologique, traduisant une forte homogénéité morphologique. D’autres, comme le cluster 7, apparaissent plus mixtes, regroupant plusieurs types, ce qui peut refléter une zone de transition morphologique ou une plus grande variabilité au sein du groupe. Globalement, la méthode de mélange permet une classification plus fine et mieux adaptée à la diversité biologique, en révélant des sous-structures que la CAH ne distinguait pas aussi clairement. table(df$melange_clusters, df$type) FALSE FALSE P R SO SW T W FALSE 1 0 28 0 15 2 19 FALSE 2 0 0 0 42 0 15 FALSE 3 0 0 0 12 0 0 FALSE 4 0 5 0 32 2 4 FALSE 5 24 0 13 0 3 1 FALSE 6 0 0 41 8 0 6 FALSE 7 12 17 7 7 7 15 FALSE 8 2 0 0 0 9 3 FALSE 9 0 0 67 0 0 2 4.4 Clustering spectral Cette répartition montre que les clusters ne correspondent pas exactement aux types réels, mais certains groupes sont mieux identifiés que d’autres (le cluster 1 par exemple) table(df$spectral_cluster, df$type) FALSE FALSE P R SO SW T W FALSE 1 38 20 128 69 20 53 FALSE 2 0 11 0 14 0 9 FALSE 3 0 0 0 5 2 2 FALSE 4 0 4 0 13 0 0 FALSE 5 0 15 0 5 1 1 FALSE 6 0 0 0 10 0 0 "],["profils-morphologiques.html", "Chapter 5 Profils Morphologiques 5.1 CAH 5.2 K-means 5.3 Méthode de mélanges 5.4 Méthode Clustering spectral", " Chapter 5 Profils Morphologiques 5.1 CAH Le groupe 4 se distingue nettement par des valeurs très élevées, traduisant une morphologie particulièrement développée. Le groupe 3 montre aussi une morphologie marquée, mais de manière plus modérée. Le groupe 1 correspond à un profil morphologique moyen, tandis que le groupe 2 regroupe les individus aux valeurs les plus faibles, représentant une morphologie réduite. aggregate(df_scale, by = list(cluster = df$ward_clusters), FUN = mean) FALSE cluster huml humw ulnal ulnaw feml femw FALSE 1 1 0.3449245 0.3193774 0.2901078 0.3937698 0.4107571 0.2418769 FALSE 2 2 -0.6232915 -0.6389203 -0.5954750 -0.6596609 -0.6294101 -0.6389385 FALSE 3 3 1.3155236 1.4171947 1.2975933 1.4801766 1.2831539 1.5460536 FALSE 4 4 3.2712302 3.1609652 3.2065300 2.4751707 3.0222379 2.9371398 FALSE tibl tibw tarl tarw FALSE 1 0.4117912 0.2906418 0.4805613 0.1864283 FALSE 2 -0.6395618 -0.6526219 -0.5736215 -0.5927879 FALSE 3 1.2866869 1.5264213 0.9308379 1.5290549 FALSE 4 3.2635290 2.9705854 3.5507774 2.3663449 5.2 K-means Le modèle K-means a identifié trois groupes distincts. Le groupe 2 présente des valeurs élevées, représentant des oiseaux à morphologie développée. Le groupe 3 regroupe des individus aux faibles valeurs, suggérant une morphologie réduite. Le groupe 1 montre des valeurs intermédiaires, correspondant à un profil morphologique moyen. Cette classification reflète une structure nette et cohérente des données. aggregate(df_scale, by = list(cluster = df$kmean_clusters), FUN = mean) FALSE cluster huml humw ulnal ulnaw feml femw FALSE 1 1 0.3471815 0.3414277 0.2722285 0.4337039 0.4196397 0.3323198 FALSE 2 2 1.7530236 1.8682067 1.7892604 1.7532666 1.7251574 1.9217736 FALSE 3 3 -0.6442161 -0.6715933 -0.6145458 -0.6895664 -0.6747891 -0.6809587 FALSE tibl tibw tarl tarw FALSE 1 0.4849416 0.4352083 0.4655577 0.2705841 FALSE 2 1.5876741 1.7707979 1.3599309 1.8231521 FALSE 3 -0.6726962 -0.6949791 -0.6024652 -0.6226267 5.3 Méthode de mélanges Les clusters 1, 3 et 4 se distinguent par des valeurs moyennes élevées, suggérant des individus de grande taille ou aux caractéristiques marquées. À l’inverse, les clusters 5 à 9 présentent des valeurs plus faibles, indiquant des morphotypes plus petits ou moins développés. Le cluster 2, aux valeurs proches de zéro, pourrait correspondre à un groupe de transition morphologique. aggregate(df_scale, by = list(cluster = df$melange_clusters), FUN = mean) FALSE cluster huml humw ulnal ulnaw feml femw FALSE 1 1 0.6303266 0.7464078 0.6288092 0.7422461 1.120926221 0.94744983 FALSE 2 2 0.4176068 0.2612711 0.3426455 0.3280377 -0.008534666 -0.05657394 FALSE 3 3 1.3125876 0.7239038 0.7513817 1.0632568 0.321938823 1.20512829 FALSE 4 4 1.7983790 1.9769801 1.8429188 1.9071720 1.500419869 1.75784978 FALSE 5 5 -0.6642725 -0.5983390 -0.5923108 -0.6683957 -0.721188607 -0.65545600 FALSE 6 6 -0.7028528 -0.7470690 -0.6577016 -0.7329421 -0.671616483 -0.67292228 FALSE 7 7 -0.3784600 -0.2981621 -0.3574167 -0.2737650 -0.131946925 -0.25713433 FALSE 8 8 -0.5836114 -0.5087668 -0.6872304 -0.6063773 0.044464203 -0.29400081 FALSE 9 9 -0.8487435 -0.9309504 -0.7931164 -0.9705701 -0.944527995 -0.90937667 FALSE tibl tibw tarl tarw FALSE 1 0.8926811 0.91553024 1.02030641 0.81441508 FALSE 2 0.2138595 0.05306191 0.09913289 -0.07699279 FALSE 3 2.2817314 2.04713913 1.44132604 0.37917414 FALSE 4 1.2719460 1.59902294 0.91622777 2.05610766 FALSE 5 -0.8249247 -0.71483654 -0.77737710 -0.64070670 FALSE 6 -0.5822847 -0.70251570 -0.41064799 -0.64515219 FALSE 7 -0.3094855 -0.29085573 -0.25245833 -0.26308091 FALSE 8 -0.2816503 -0.35261562 -0.27879314 -0.28415895 FALSE 9 -0.8911421 -0.91526403 -0.76627385 -0.83863574 5.4 Méthode Clustering spectral L’analyse des profils morphologiques issus du clustering spectral met en évidence une hétérogénéité structurée de la population aviaire étudiée. Chaque cluster reflète un morphotype distinct, allant de spécimens de petite taille (cluster 1) à des individus nettement plus imposants (cluster 6), en passant par des groupes intermédiaires présentant des particularités morphologiques marquées. Cette segmentation suggère l’existence de sous-populations bien différenciées, probablement liées à des adaptations écologiques, fonctionnelles ou évolutives spécifiques. aggregate(df_scale, by = list(cluster = df$spectral_cluster), FUN = mean) FALSE cluster huml humw ulnal ulnaw feml femw FALSE 1 1 -0.3914801 -0.4121727 -0.3896227 -0.4032834 -0.4058545 -0.4481694 FALSE 2 2 0.8895843 0.6938525 0.7969972 0.7441776 0.9246601 0.9602549 FALSE 3 3 0.6068858 2.1672801 0.3991893 2.0840616 2.1485319 2.0042751 FALSE 4 4 1.9198326 2.0762783 2.3409237 2.0504207 1.2529092 1.9580344 FALSE 5 5 1.0827494 1.2578900 1.1105167 1.2395059 1.8109257 1.7581531 FALSE 6 6 3.6240011 2.9125829 3.2878555 2.6092070 2.1205241 2.4346462 FALSE tibl tibw tarl tarw FALSE 1 -0.4056592 -0.4428987 -0.35523239 -0.4223797 FALSE 2 1.3725918 1.2403450 1.34001786 0.5712772 FALSE 3 2.1234205 1.7966497 1.88072738 3.1380124 FALSE 4 0.6427317 1.3296956 0.09185753 2.0101355 FALSE 5 1.3217959 1.6178743 1.37419649 1.6709788 FALSE 6 2.7271365 2.8731135 2.22351681 1.9941169 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
